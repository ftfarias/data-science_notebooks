{
 "metadata": {
  "name": "",
  "signature": "sha256:4af4a61abaff1daebc55b3c3b955545004df15d4a18014f96aaeb1ed3118faa9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Valida\u00e7\u00e3o cruzada"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Primeiro vamos explorar como fazer valida\u00e7\u00e3o cruzada com o UCI digits dataset.\n",
      "Esse dataset corresponde a 64 features (8x8 pixels) e 10 classes (10 labels correspondendo aos d\u00edgitos 0-9)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import datasets, linear_model, cross_validation, grid_search\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Vamos utilizar somente 1000 inst\u00e2ncias do dataset. Como pode ser visto utilizando shape, o dataset possui 1000 inst\u00e2ncias e 64 features. Em y temos um vetor com as labels de cada elemento de x."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "digits = datasets.load_digits()\n",
      "x = digits.data[:1000]\n",
      "y = digits.target[:1000]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(x.shape)\n",
      "print(y.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1000, 64)\n",
        "(1000,)\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Valida\u00e7\u00e3o cruzada \u00e9 utilizada para validar seus modelos utilizando diferentes combina\u00e7\u00f5es dos dados que voc\u00ea possui. Por exemplo, se voc\u00ea possui 100 inst\u00e2ncias, voc\u00ea poderia utilizar as inst\u00e2ncias de [1,90] como treino e gerar um modelo e utilizar as inst\u00e2ncias [91,100] como teste para verificar o desempenho do seu modelo. Em seguida voc\u00ea poderia repetir esse processo, mas utilizando as inst\u00e2ncias [1,80] e [91,100] para treinar seu modelo e as inst\u00e2ncias [81,90] para teste. Se voc\u00ea repetir esse processo sucessivamente teremos 10 combina\u00e7\u00f5es diferentes para testar a generalidade do nosso modelo."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Esse processo de dividir nosso dataset em 10 partes \u00e9 mais conhecido como 10-fold cross-validation. Se em vez de 10 partes divid\u00edssimos em 5 ter\u00edamos 5-fold cross validation. Fazer k-fold cross validation em python (utilizando scikit-learn) \u00e9 f\u00e1cil:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "kf_total = cross_validation.KFold(len(x), n_folds=10, indices=True, shuffle=True, random_state=4)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/site-packages/sklearn/cross_validation.py:64: DeprecationWarning: The indices parameter is deprecated and will be removed (assumed True) in 0.17\n",
        "  stacklevel=1)\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "No m\u00e9todo acima: len(x) determina que usaremos todo o dataset para a valida\u00e7\u00e3o cruzada (1000 inst\u00e2ncias); n_folds=10 determina que dividiremos nosso conjunto de dados em 10 partes; indices=True indica que queremos que o m\u00e9todo retorne os \u00edndices dos elementos do dataset no array (x) e n\u00e3o os elementos; shuffle=True determina que as inst\u00e2ncias de teste n\u00e3o seguiram uma ordem pr\u00e9-definida; random_state=4 controla o n\u00edvel de aleatoriedade."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Uma forma simples de avaliar a generalidade de um modelo seria testa-lo em cada um desses 10 testes e verificar os scores (acur\u00e1cia) de cada um desses testes (ou a sua m\u00e9dia):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr = linear_model.LogisticRegression()\n",
      "resultados = [lr.fit(x[train_indices], y[train_indices]).score(x[test_indices],y[test_indices]) for train_indices, test_indices in kf_total]\n",
      "print resultados\n",
      "print np.mean(resultados)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0.95999999999999996, 0.95999999999999996, 0.98999999999999999, 0.96999999999999997, 0.97999999999999998, 0.96999999999999997, 0.93999999999999995, 0.94999999999999996, 0.94999999999999996, 0.96999999999999997]\n",
        "0.964\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ou de forma mais simples usando a pr\u00f3pria funcionalidade do sklearn:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resultados =  cross_validation.cross_val_score(lr, x, y, cv=kf_total, n_jobs = 1)\n",
      "print resultados\n",
      "print np.mean(resultados)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 0.96  0.96  0.99  0.97  0.98  0.97  0.94  0.95  0.95  0.97]\n",
        "0.964\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Al\u00e9m de poder verificar a generalidade do modelo, voc\u00ea pode utilizar para comparar algoritmos:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import GaussianNB\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "\n",
      "nb = GaussianNB()\n",
      "knn = KNeighborsClassifier()\n",
      "tree = DecisionTreeClassifier()\n",
      "\n",
      "resultados_naive_bayes =  cross_validation.cross_val_score(nb, x, y, cv=kf_total, n_jobs = 1)\n",
      "resultados_knn =  cross_validation.cross_val_score(knn, x, y, cv=kf_total, n_jobs = 1)\n",
      "resultados_tree =  cross_validation.cross_val_score(tree, x, y, cv=kf_total, n_jobs = 1)\n",
      "\n",
      "print \"Resultados Naive Bayes: \", np.mean(resultados_naive_bayes)\n",
      "print \"Resultados KNN: \", np.mean(resultados_knn)\n",
      "print \"Resultados Decision Trees: \", np.mean(resultados_tree)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Resultados Naive Bayes:  0.795\n",
        "Resultados KNN:  0.983\n",
        "Resultados Decision Trees:  0.812\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Otimiza\u00e7\u00e3o de par\u00e2metros"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Muito algoritmos de machine learning precisam ser otimizados (encontrar os par\u00e2metros corretos para um dataset). Um m\u00e9todo muito \u00fatil do scikit-learn \u00e9 o GridSearchCV. Com ele podemos fazer uma busca exaustiva dos melhores par\u00e2metros para um modelo."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Por exemplo, um dos par\u00e2metros do linear_model.LinearRegression \u00e9 o C. O C \u00e9 inverso da \"for\u00e7a\" da regulariza\u00e7\u00e3o. Em outras palavras, menor o C mais forte \u00e9 a regulariza\u00e7\u00e3o."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "c_range = np.logspace(0, 4, 10)\n",
      "print c_range\n",
      "lrgs = grid_search.GridSearchCV(estimator=lr, param_grid=dict(C=c_range), n_jobs=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[  1.00000000e+00   2.78255940e+00   7.74263683e+00   2.15443469e+01\n",
        "   5.99484250e+01   1.66810054e+02   4.64158883e+02   1.29154967e+03\n",
        "   3.59381366e+03   1.00000000e+04]\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Na linha acima, c_range determina o alcance dos valores a serem avaliados para o par\u00e2metro. Nesse caso, teremos 10 valores igualmente distantes entre 0 e 4 numa escala log."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "O segundo m\u00e9todo faz a otimiza\u00e7\u00e3o. estimator=lr determina o tipo de modelo que voc\u00ea quer otimizar. Em vez de usar o lr que j\u00e1 foi declarado anteriormente, voc\u00ea poderia criar um modelo novo: estimator=linear_model.LogisticRegression(); param_grid=dict(C=c_range) \u00e9 um dicion\u00e1rio com o par\u00e2metro que voc\u00ea quer otimizar e os seus respectivos valores a serem testados. Em vez de um dicion\u00e1rio, voc\u00ea poderia utilizar uma lista de dicion\u00e1rios para testas outros par\u00e2metros; n_jobs=1 \u00e9 o n\u00famero de CPUs a serem utilizados na otimiza\u00e7\u00e3o."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Com isso podemos procurar nosso modelo \"tunado\":"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resultados_lrgs = [lrgs.fit(x[train_indices], y[train_indices]).score(x[test_indices],y[test_indices]) for train_indices, test_indices in kf_total]\n",
      "#resultados_lrgs = cross_validation.cross_val_score(lrgs, x, y, cv=kf_total, n_jobs=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(resultados_lrgs)\n",
      "print(np.mean(resultados_lrgs))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[0.95999999999999996, 0.94999999999999996, 0.98999999999999999, 0.96999999999999997, 0.97999999999999998, 0.96999999999999997, 0.93999999999999995, 0.94999999999999996, 0.94999999999999996, 0.96999999999999997]\n",
        "0.963\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Para finalizar, \u00e9 poss\u00edvel verificar quais foram os valores dos par\u00e2metros utilizados pelo modelo:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print lrgs.best_params_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'C': 1.0}\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}