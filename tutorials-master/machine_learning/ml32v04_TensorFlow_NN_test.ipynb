{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".text_cell_render @font-face {\n",
       "    font-family: \"Computer Modern\";\n",
       "    src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
       "}\n",
       "\n",
       "div.cell {\n",
       "    width: 900px;\n",
       "    margin-left: 0% !important;\n",
       "    margin-right: 0%;\n",
       "}\n",
       "\n",
       "code {\n",
       "    font-size:10pt;\n",
       "}\n",
       "\n",
       ".text_cell_render  h1 {\n",
       "    font-family: Tahoma, sans-serif;\n",
       "    color: rgb( 10, 88, 126 );\n",
       "    font-size:28pt;\n",
       "}\n",
       ".text_cell_render h2 {\n",
       "    font-family: Tahoma, sans-serif;\n",
       "    color: rgb( 10, 88, 126 );\n",
       "    font-size:24pt;\n",
       "}\n",
       ".text_cell_render h3 {\n",
       "    font-family: Tahoma, sans-serif;\n",
       "    color: rgb( 10, 88, 126 );\n",
       "    font-size:20pt;\n",
       "}\n",
       ".text_cell_render h4 {\n",
       "    font-family: Tahoma, sans-serif;\n",
       "    color: rgb( 10, 88, 126 );\n",
       "    font-size:18pt;\n",
       "    margin-top:12px;\n",
       "    margin-bottom: 3px;\n",
       "}\n",
       "\n",
       ".text_cell_render h5 {\n",
       "    font-weight: 300;\n",
       "    font-size: 11pt;\n",
       "    color: rgb( 48, 48, 48 );\n",
       "    font-style: italic;\n",
       "    margin-bottom: .5em;\n",
       "    margin-top: 0.5em;\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".text_cell_render ul {\n",
       "    font-family: Tahoma, sans-serif;\n",
       "    color: rgb( 90, 90, 90 );\n",
       "    font-size:11pt;\n",
       "    line-height: 185%;\n",
       "}\n",
       "\n",
       ".text_cell_render yp {\n",
       "    font-family: Tahoma, sans-serif;\n",
       "    color: rgb( 90, 90, 90 );\n",
       "    font-size:11pt;\n",
       "}\n",
       "\n",
       ".text_cell_render strong {\n",
       "    font-family: Tahoma, sans-serif;\n",
       "    color: rgb( 30, 30, 30 );\n",
       "    font-size:11pt;\n",
       "}\n",
       "\n",
       ".text_cell_render a:link {\n",
       "    font-family: Tahoma, sans-serif;\n",
       "    color: rgb( 10, 88, 126 );\n",
       "    font-size:11pt;\n",
       "}\n",
       "\n",
       ".text_cell_render a:visited {\n",
       "    color:rgb( 10, 88, 126 );\n",
       "}\n",
       "\n",
       ".text_cell_render {\n",
       "    font-family: Helvetica, Courier, Computer Modern, \"Helvetica Neue\", Arial, Geneva, sans-serif;\n",
       "    color: rgb( 84, 84, 84 );\n",
       "    font-size:11pt;\n",
       "    line-height: 125%;\n",
       "    font-size: 100%;\n",
       "    width:800px;\n",
       "}\n",
       "\n",
       ".CodeMirror {\n",
       "    font-family: Courier, \"Source Code Pro\", source-code-pro,Consolas, monospace;\n",
       "}\n",
       "\n",
       ".warning {\n",
       "    color: rgb( 240, 20, 20 );\n",
       "}\n",
       "\n",
       "/* Pandas tables */\n",
       "/*\n",
       ".rendered_html td {\n",
       "    text-align: right;\n",
       "}\n",
       "*/\n",
       "\n",
       "table.dataframe td {\n",
       "    text-align: right;\n",
       "}\n",
       "\n",
       ".output .table-of-contents {\n",
       "    border: 1px #cecece solid;\n",
       "    background-color: #fafafa;\n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 5px;\n",
       "    padding-right: 15px;\n",
       "    padding-left: 0px;\n",
       "    margin-bottom: 20px;\n",
       "    display: inline-block;\n",
       "    position: relative;\n",
       "}\n",
       "\n",
       ".output .table-of-contents ul {\n",
       "    list-style-type: none;\n",
       "    padding-left: 20px;\n",
       "}\n",
       "\n",
       ".output .table-of-contents .title {\n",
       "    font-weight: bold;\n",
       "    font-height: 11pt;\n",
       "    padding-left: 20px; /* looks better if it's the same to the <ul> */\n",
       "}\n",
       "\n",
       ".output .table-of-contents .btn-update {\n",
       "    position: absolute;\n",
       "    float: right;\n",
       "    right: 11px;\n",
       "    top: 4px;\n",
       "    font-size: 9pt;\n",
       "}\n",
       "\n",
       "</style>\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"]\n",
       "                           },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import sklearn.metrics\n",
    "from IPython.display import Image\n",
    "from addutils import css_notebook\n",
    "import time\n",
    "import json\n",
    "css_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "    <script type=\"text/javascript\">\n",
       "      \n",
       "      (function(global) {\n",
       "        function now() {\n",
       "          return new Date();\n",
       "        }\n",
       "      \n",
       "        if (typeof (window._bokeh_onload_callbacks) === \"undefined\") {\n",
       "          window._bokeh_onload_callbacks = [];\n",
       "        }\n",
       "      \n",
       "        function run_callbacks() {\n",
       "          window._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "          delete window._bokeh_onload_callbacks\n",
       "          console.info(\"Bokeh: all callbacks have finished\");\n",
       "        }\n",
       "      \n",
       "        function load_libs(js_urls, callback) {\n",
       "          window._bokeh_onload_callbacks.push(callback);\n",
       "          if (window._bokeh_is_loading > 0) {\n",
       "            console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "            return null;\n",
       "          }\n",
       "          if (js_urls == null || js_urls.length === 0) {\n",
       "            run_callbacks();\n",
       "            return null;\n",
       "          }\n",
       "          console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "          window._bokeh_is_loading = js_urls.length;\n",
       "          for (var i = 0; i < js_urls.length; i++) {\n",
       "            var url = js_urls[i];\n",
       "            var s = document.createElement('script');\n",
       "            s.src = url;\n",
       "            s.async = false;\n",
       "            s.onreadystatechange = s.onload = function() {\n",
       "              window._bokeh_is_loading--;\n",
       "              if (window._bokeh_is_loading === 0) {\n",
       "                console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "                run_callbacks()\n",
       "              }\n",
       "            };\n",
       "            s.onerror = function() {\n",
       "              console.warn(\"failed to load library \" + url);\n",
       "            };\n",
       "            console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "            document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          }\n",
       "        };var js_urls = ['https://cdn.pydata.org/bokeh/release/bokeh-0.11.0.min.js', 'https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.11.0.min.js', 'https://cdn.pydata.org/bokeh/release/bokeh-compiler-0.11.0.min.js'];\n",
       "      \n",
       "        var inline_js = [\n",
       "          function(Bokeh) {\n",
       "            Bokeh.set_log_level(\"info\");\n",
       "          },\n",
       "          function(Bokeh) {\n",
       "            console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.11.0.min.css\");\n",
       "            Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.11.0.min.css\");\n",
       "            console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.11.0.min.css\");\n",
       "            Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.11.0.min.css\");\n",
       "          }\n",
       "        ];\n",
       "      \n",
       "        function run_inline_js() {\n",
       "          for (var i = 0; i < inline_js.length; i++) {\n",
       "            inline_js[i](window.Bokeh);\n",
       "          }\n",
       "        }\n",
       "      \n",
       "        if (window._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "          run_inline_js();\n",
       "        } else {\n",
       "          load_libs(js_urls, function() {\n",
       "            console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "            run_inline_js();\n",
       "          });\n",
       "        }\n",
       "      }(this));\n",
       "    </script>\n",
       "    <div>\n",
       "        <a href=\"http://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span>BokehJS successfully loaded.</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import bokeh.plotting as bk\n",
    "bk.output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 TensorFlow Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this serie of notebooks we would like to compare three different libraries for Neural Netwok using a regression problem on temporal data. The problem is to predict the value of the next event using a fully connected feed forward network. Each notebook performs the fitting and prediction of the data using a different library, varying batch size and recording both precision (RMSE) and the time needed to fit the data. \n",
    "\n",
    "This notebook uses TensorFlow. Please refer to previous notebooks in the serie for installation instructions and how-tos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For this serie of tests we used a dataset with more examples and an increased model complexity. We downloaded it from the *UCI Machine Learning Repository*. Follow this link and download the [Individual household electric power consumption](http://archive.ics.uci.edu/ml/machine-learning-databases/00235/household_power_consumption.zip) dataset. It has more than two milions examples. Please download it in `tutorials/machine_learning/example_data/` and unzip it. It refers to measurements of electric power consumption in one household with a one-minute sampling rate over a period of almost 4 years. Different electrical quantities and some sub-metering values are available. In our experiment we use *Voltage* as reference quantity.\n",
    "\n",
    "Settings for this experiments are similar to the one used for previous notebooks. It is possible to choose the number of features (i.e. the number of inputs) and the number of future steps to predict. The variable `percentage` refers to the number of training examples with respect to the whole dataset. For example if you specify 0.7 it means that 70% of the examples will be used for training. The remaining 30% examples are split equally between test set and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 100\n",
    "steps_forward = 1\n",
    "percentage = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_file = 'example_data/household_power_consumption.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = pd.read_csv(input_file, sep=';', na_values='?') # automatically converting '?' to NaN removes warning\n",
    "a = x['Voltage']\n",
    "a = a[a.notnull()]\n",
    "a = a.values\n",
    "\n",
    "vec_size = n_inputs + steps_forward - 1\n",
    "\n",
    "X = np.zeros((a.size-vec_size,n_inputs))\n",
    "\n",
    "y = np.zeros((a.size-vec_size,1))\n",
    "for r in range(a.size-vec_size):\n",
    "    X[r,:] = a[r:r+n_inputs]\n",
    "    y[r,:] = a[r+vec_size]\n",
    "\n",
    "split = int(a.size*percentage) - n_inputs\n",
    "vt_split = int((X.shape[0]-split)/2)\n",
    "X_train = X[:split]\n",
    "X_test = X[split+vt_split:] \n",
    "X_valid = X[split:split+vt_split] \n",
    "y_train = y[:split]\n",
    "y_test = y[split+vt_split:]\n",
    "y_valid = y[split:split+vt_split]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: 1434396, 100\n",
      "X_test shape: 307392, 100\n",
      "X_valid shape: 307392, 100\n",
      "y_train shape: 1434396, 1\n",
      "y_test shape: 307392, 1\n",
      "y_valid shape: 307392, 1\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape: %d, %d' % X_train.shape)\n",
    "print('X_test shape: %d, %d' % X_test.shape)\n",
    "print('X_valid shape: %d, %d' % X_valid.shape)\n",
    "print('y_train shape: %d, %d' % y_train.shape)\n",
    "print('y_test shape: %d, %d' % y_test.shape)\n",
    "print('y_valid shape: %d, %d' % y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test varying batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following section we perform fitting and prediction of the dataset, using several batch sizes and for each size we record execution time and error. The error measure is Root Mean Squared Error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The architecture of the Neural Network is composed as follows:\n",
    "\n",
    "* Two hidden layers\n",
    "* First hidden layer with 100 neurons\n",
    "* Second hidden layer with 50 neurons\n",
    "* Dropout with p=0.5 in each layer\n",
    "* Gradient Descent with momentum \n",
    "* Learning Rate = 0.01\n",
    "* Momentum = 0.9\n",
    "* Eearly Stopping\n",
    "* One neuron with linear activation in output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `fit_predict` creates a neural network with the specific architecture and a given batch size and perform fitting and prediction on the dataset. It return the error measure and the time elapsed during fitting.\n",
    "\n",
    "The TensorFlow implementation translates the graph definition into executable operations distributed across available computing resources, such as the CPU or one of the GPU cards. In general you do not have to specify CPUs or GPUs explicitly, because TensorFlow uses the first GPU, if there is one, for as many operations as possible.\n",
    "\n",
    "For the purpose of this benchmark, however, we would like to specify to run the computation on a single device, such as CPU only, as much as TensorFlow allows us to do it. In order to choose which device to use, CPU or GPU, please change the variable `device` in the cell below. To select CPU use the keyword `/cpu:0`, while with keyword `/gpu:0` it is possible to select the first GPU. If you have more than one GPU installed on your machine, refer to it using the number after the colon, for example the second GPU is `/gpu:1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device = '/gpu:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fit_predict(batch_size, X_train, y_train, X_test, y_test, X_valid, y_valid):\n",
    "    epochs = 100\n",
    "    hidden_size1 = 100\n",
    "    hidden_size2 = 50\n",
    "    p = 0.5\n",
    "\n",
    "    n_inputs = X_train.shape[1]\n",
    "\n",
    "    with tf.device(device):\n",
    "        x = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "        y_ = tf.placeholder(tf.float32, [None, 1])\n",
    "        keep_prob = tf.placeholder(\"float\")\n",
    "\n",
    "        W1_x = tf.Variable(tf.truncated_normal([n_inputs, hidden_size1], stddev=0.05))\n",
    "        b1_h = tf.Variable(tf.constant(0.1, shape=[hidden_size1]))\n",
    "\n",
    "        h1 = tf.nn.tanh(tf.matmul(x, W1_x) + b1_h)\n",
    "        h1_drop = tf.nn.dropout(h1, keep_prob)\n",
    "\n",
    "        W2_x = tf.Variable(tf.truncated_normal([hidden_size1, hidden_size2], stddev=0.05))\n",
    "        b2_h = tf.Variable(tf.constant(0.1, shape=[hidden_size2]))\n",
    "\n",
    "        h2 = tf.nn.tanh(tf.matmul(h1_drop, W2_x) + b2_h)\n",
    "        h2_drop = tf.nn.dropout(h2, keep_prob)\n",
    "\n",
    "        W_h = tf.Variable(tf.zeros([hidden_size2, 1]))\n",
    "\n",
    "        b_y = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "        y = tf.matmul(h2_drop, W_h) + b_y\n",
    "\n",
    "    loss = tf.reduce_mean(tf.square(y - y_))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.01) # learning rate         \n",
    "    train = optimizer.minimize(loss)\n",
    "\n",
    "    sess = tf.Session()\n",
    "\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    train_batches = len(X_train) // batch_size \n",
    "    t0 = time.time()\n",
    "    prev = None\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(train_batches):\n",
    "            batch_x = X_train[i*batch_size:(i+1)*batch_size]\n",
    "            batch_y = y_train[i*batch_size:(i+1)*batch_size]\n",
    "            sess.run(train, feed_dict={x: batch_x, y_:batch_y, keep_prob:p})\n",
    "        preds = sess.run(y, feed_dict={x: X_valid, keep_prob: 1.0})\n",
    "        curr = np.sqrt(sk.metrics.mean_squared_error(preds, y_valid))\n",
    "        if (prev == None):\n",
    "            prev = curr\n",
    "        else:\n",
    "            if curr > prev:\n",
    "                break\n",
    "            prev = curr\n",
    "\n",
    "    fit_time = time.time() - t0\n",
    "\n",
    "    preds = sess.run(y, feed_dict={x: X_test, keep_prob: 1.0})\n",
    "    err = np.sqrt(sk.metrics.mean_squared_error(preds, y_test))\n",
    "    return fit_time, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tensorflow_result = {'batch_size':[], 'error':[], 'fit_time':[]}\n",
    "for batch in [128, 256, 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536, 131072]:\n",
    "    tensorflow_result['batch_size'].append(batch)\n",
    "    t, err = fit_predict(batch, X_train, y_train, X_test, y_test, X_valid, y_valid)\n",
    "    tensorflow_result['error'].append(err)\n",
    "    tensorflow_result['fit_time'].append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>error</th>\n",
       "      <th>fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>3.605597</td>\n",
       "      <td>145.099285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>256</td>\n",
       "      <td>3.547923</td>\n",
       "      <td>94.896823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>512</td>\n",
       "      <td>2.702137</td>\n",
       "      <td>101.889646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1024</td>\n",
       "      <td>2.767090</td>\n",
       "      <td>54.535229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2048</td>\n",
       "      <td>2.695520</td>\n",
       "      <td>44.514253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4096</td>\n",
       "      <td>3.110668</td>\n",
       "      <td>18.167414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8192</td>\n",
       "      <td>4.126063</td>\n",
       "      <td>5.683449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16384</td>\n",
       "      <td>4.635352</td>\n",
       "      <td>5.589076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32768</td>\n",
       "      <td>4.846756</td>\n",
       "      <td>3.359841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>65536</td>\n",
       "      <td>4.423262</td>\n",
       "      <td>2.580113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>131072</td>\n",
       "      <td>5.166029</td>\n",
       "      <td>1.687670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    batch_size     error    fit_time\n",
       "0          128  3.605597  145.099285\n",
       "1          256  3.547923   94.896823\n",
       "2          512  2.702137  101.889646\n",
       "3         1024  2.767090   54.535229\n",
       "4         2048  2.695520   44.514253\n",
       "5         4096  3.110668   18.167414\n",
       "6         8192  4.126063    5.683449\n",
       "7        16384  4.635352    5.589076\n",
       "8        32768  4.846756    3.359841\n",
       "9        65536  4.423262    2.580113\n",
       "10      131072  5.166029    1.687670"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tensorflow_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the name and location of the destination file where results will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_file = 'temp/tensorflow.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(output_file, 'w') as fp:\n",
    "    json.dump(tensorflow_result, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "Visit [www.add-for.com](<http://www.add-for.com/IT>) for more tutorials and updates.\n",
    "\n",
    "This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
