{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split apply and combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import addutils.toc ; addutils.toc.js(ipy_notebook=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial we are going to see advanced data management with `pandas` data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import (display, HTML)\n",
    "from addutils import side_by_side2\n",
    "from addutils import css_notebook\n",
    "css_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorizing a data set and applying a function to each group, is often a critical component of a data analysis workflow. After\n",
    "loading, merging, and preparing a data set, a familiar task is to compute group statistics or possibly pivot tables for reporting or visualization purposes. *pandas* provides a flexible and high-performance groupby facility.\n",
    "\n",
    "By *'group by'* we refer to a process involving one or more of the following steps:\n",
    "\n",
    "* **Splitting** the data into groups based on some criteria\n",
    "* **Applying** a function to each group independently\n",
    "* **Combining** the results into a data structure\n",
    "\n",
    "Suppose we are managing a website and we have a log-file with number of *wiews* and *likes* coming from different cities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d1 = pd.read_csv('temp/p07_d1.txt', index_col=0)\n",
    "d1 = d1.reindex(columns=['State','City','Views','Likes'])\n",
    "display(d1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`groupby` groups DataFrame or Series by a parameter on a given axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g1 = d1.groupby('State')\n",
    "print (g1.groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `groups` of a `GroupBy` object is a dictionary containing indexes of each group member."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for name,group in g1:\n",
    "    print (name)\n",
    "    print (group)\n",
    "    print ('Total Views: %d - Total Likes: %d\\n\\n' %(group['Views'].sum(),\n",
    "                                                    group['Likes'].sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possibile to apply a `groupby` over a hierarchical index `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d2 = d1.set_index(['State','City'])\n",
    "display(d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Aggregate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the GroupBy object has been created, several methods are available to perform a computation on the grouped data. Here we use `aggregate`. The result of the aggregation will have the group names as the new index along the grouped axis. In the case of multiple keys, the result is a MultiIndex by default, though this can be changed by using the `as_index option`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g2 = d2.groupby(level=[0])\n",
    "print (g2.groups)\n",
    "g2.aggregate(np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g3 = d2.groupby(level=[0,1])\n",
    "g4 = d2.groupby(level=[0,1], as_index=False)\n",
    "HTML(side_by_side2(g3.aggregate(np.sum), g4.aggregate(np.sum)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`aggregate` allows to pass any function that returns a scalar value from a vector and can handle list of functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d1[['State', 'Views']].groupby('State').aggregate([np.sum, np.mean, np.std])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Apply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`apply` will extend the previous concepts to any Python function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '{:.1f}'.format(x))\n",
    "\n",
    "def add_field(group):\n",
    "    group['Tot.Views'] = group['Views'].sum()\n",
    "    group['Likes[%]'] = 100.0*group['Likes']/group['Likes'].sum()\n",
    "    return group\n",
    "\n",
    "HTML(side_by_side2(d1, d1.groupby('State').apply(add_field)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 A pratical example: Normalize by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = pd.date_range('1999/5/28', periods=1500, freq='1B')\n",
    "s1 = pd.Series(np.random.normal(5.5, 2, 1500), idx)\n",
    "s1 = s1.rolling(10,10).mean().dropna()\n",
    "#s1 = s1.rolling_mean(s1, 10, 10).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a grouping key for months and one for years:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def my_groupby_key_year(timestamp):\n",
    "    return timestamp.year\n",
    "\n",
    "def my_groupby_key_month(timestamp):\n",
    "    return timestamp.month\n",
    "\n",
    "def my_normalization(group):\n",
    "    return (group-group.mean())/group.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we normalize the data on a monthly base and check mean and std on an yearly base:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t1 = s1.groupby(my_groupby_key_month).apply(my_normalization)\n",
    "\n",
    "HTML(side_by_side2(s1.head(8),\n",
    "                  t1.head(8),\n",
    "                  t1.groupby(my_groupby_key_year).aggregate([np.mean, np.std])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 A practical example: Group and standardize by dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d3 = pd.read_csv('example_data/company.csv', index_col=0)\n",
    "display(d3.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the column \"Value\" is made by strings with a space separator we need a simpel intermediate step to convert values from string to floats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d3['Value'] = d3['Value'].apply(lambda x: float(x.replace(' ', '')))\n",
    "d3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d3.groupby('Dimension').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Visit [www.add-for.com](<http://www.add-for.com/IT>) for more tutorials and updates.\n",
    "\n",
    "This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
