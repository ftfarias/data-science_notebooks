{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unicode in Python 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import addutils.toc ; addutils.toc.js(ipy_notebook=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from addutils import css_notebook\n",
    "css_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 The World and Unicode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are five unavoidable facts to take in consideration:\n",
    "\n",
    "**Computers are built on Bytes**\n",
    "\n",
    "It's not possible to send Unicode to someone: the only thing possible is to send bytes. You don't send text: you send bytes.\n",
    "\n",
    "To send text to people what we decided to do, because bytes are meaningless, is to assign meaning to bytes. The most known convenction id the *ASCII* code that takes 95 graphic symbols and maps it to bytes values. Other codings assigned more values: *ISO 8859-1= added 96 more characters and *Windows-1252* added 27 more characters.\n",
    "\n",
    "**256 Symbols are not enough for the world to communicate text**\n",
    "\n",
    "There a lot of languages in the world and it's not possible to ask everyone to speak English!\n",
    "\n",
    "To deal with more than 256 symbols the first idea was to make new single-bytes codes. Thea was infeasible because many different codes where made at the same time, not to mention alphabets with more than 256 symbols. Next idea was dealing with two-bytes codes but this generated problems anyway.\n",
    "\n",
    "We end-up by making *Unicode*. Unicode is foundamentally a giant catalogue of symbols assigned to integers called *code points* that are written with \"U+\" HEX Digit, example `U+03B1` is the greek letter alpha. The structure of Unicode allows 1.1M characters of which 110K has been assigned so far, so we used nearly 10% of the available space and we covered all the world languages.\n",
    "\n",
    "What we have to do is to figure out how to map this 1.1M integers in bytes. This is done by encodings: encodings are ways to map integer to bytes and vice-versa.\n",
    "\n",
    "There is a number of different encodings (UTF-8, UTF-7, UTF-16, UTF-32, UCS-2, UCS-4) but the king of all the encodings is *UTF-8*.\n",
    "\n",
    "**UTF-8** is the most important encoding you must know about: is variable lenght (from one to four bytes) and ASCII character are still represented by one byte. This means that ASCII strings are valid UTF-8 strings.\n",
    "\n",
    "**UTF-8** is a multibyte encoding able to encode the whole Unicode charset. An encoded character takes between 1 and 4 bytes. UTF-8 encoding supports longer byte sequences, up to 6 bytes, but the biggest code point of Unicode 6.0 (U+10FFFF) only takes 4 bytes.\n",
    "\n",
    "It is possible to be sure that a byte string is encoded to UTF-8, because UTF-8 adds markers to each byte. For the first byte of a multibyte character, bit 7 and bit 6 are set `(0b11xxxxxx)`; the next bytes have bit 7 set and bit 6 unset `(0b10xxxxxx)`.\n",
    "\n",
    "* **UCS-2** and **UCS-4** encodings encode each code point to exactly one unit.\n",
    "* **UTF-16** and **UTF-32** encodings use, respectivelly, 16 and 32 bits units.\n",
    "* **UTF-7** encoding is similar to the **UTF-8** encoding, except that it uses 7 bits units instead of 8 bits units. It is used for example in emails with server which are not “8 bits clean”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Encoding and decoding in Python 3.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python 2.x there were two distinct datatypes: one for storing *bytes* which is called `str` and one for storing *Unicode code points*, called `unicode`.\n",
    "\n",
    "In Python 3 there are still two datatypes: one for strings (sequence of code points) and one for bytes (sequence of bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_string = u'This is a string: ' + '\\u2020\\u212f\\u2716t'\n",
    "print('{:15s} : {:s}'.format(str(type(my_string)), my_string))\n",
    "\n",
    "my_bytes = b'Hello world'\n",
    "print('{:15s} : {:}'.format(str(type(my_bytes)), my_bytes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Reading files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python 3 the data you get from files depends on how you open it: there is a \"text\" mode and a \"binary\" mode for opening files. If you open with the default 'r' mode you get an unicode string, if instead you use a 'rb' mode, you get a byte string.\n",
    "\n",
    "Option: in the following code you can define a specific decoder with\n",
    "\n",
    "    open(path, 'r', encoding='utf-8').read()\n",
    "    \n",
    "Option: use the system decoder with:\n",
    "\n",
    "    open(path, 'r', encoding=locale.getpreferredencoding()).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "path = os.path.join(os.path.curdir, 'tmp', 'my_utf8_example.txt')\n",
    "with open(path, 'w', encoding='utf-8') as fid:\n",
    "    fid.write(my_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "open(path, 'r').read()\n",
    "#import locale\n",
    "#open(path, 'r', encoding=locale.getpreferredencoding()).read()\n",
    "#open(path, 'r', encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "open(path, 'rb').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Remember: you can't infer encoding from bytes: someone has to tell you the encoding:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = os.path.join(os.path.curdir, 'tmp', 'my_unknow_encoder.txt')\n",
    "with open(path, 'wb') as fid:\n",
    "    b = 'THIS IS AN ENCODING TEST'.encode('cp1252')\n",
    "    fid.write(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check https://docs.python.org/2/library/codecs.html for a full Codec list\n",
    "\n",
    "decoders = ['ascii', 'latin_1', 'cp1252', 'cp1253', 'iso2022_jp_2',\n",
    "            'UTF-8', 'UTF-7', 'UTF-16', 'UTF-32', 'UCS-2', 'UCS-4']\n",
    "for decoder in decoders:\n",
    "    try:\n",
    "        print('{:>15s}  Recognized: \"{:s}\"'.format(decoder, open(path,\n",
    "                                                 'r', encoding=decoder).read()))\n",
    "    except:\n",
    "        print('{:>15s}  Not recognized'.format(decoder))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Bytes Outside, Unicode Inside"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most safe way of dealing with unicode is to convert to unicode as soon as possible (when we get the raw data) and to convert back while sending the data out of our program.\n",
    "\n",
    "Data ca be encoded and decoded in two ways:\n",
    "\n",
    "* `'something'.encode('utf-8')`\n",
    "* `bytes('something', 'utf-8')`\n",
    "\n",
    "Neither is better than the other, they do exactly the same thing. However, using `.encode()` and `.decode()` is the more common way to do it. It is also compatible with Python 2.\n",
    "\n",
    "Encoding and decoding can be useful to go from a coding system to another:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s1 = '♈♉♊♋♌♍♎♏♐♑♒♓'\n",
    "b1 = s1.encode('utf-7') # Convert from unicode to bytes\n",
    "print(b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b1.decode('utf-7') # Convert from bytes to unicode with the Right decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b1.decode('utf-8')  # Convert from bytes to unicode with the Wrong decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just have fun and TEST with text generators: the best way to check if your code works well is to feed it with unicode strings and not just with ASCII strings. If you want to find a Text Generator just type \"fancy text generators\" on Google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = 9500\n",
    "for i in range(start, start+1000):\n",
    "    print(chr(i), end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information check this video from PyCon2012:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Video credit: Ned Batchelder\n",
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('sgHbC6udIqc', width=640, height=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Visit [www.add-for.com](<http://www.add-for.com/IT>) for more tutorials and updates.\n",
    "\n",
    "This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
